{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1def820",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2781ee43",
   "metadata": {},
   "source": [
    "### Using this [Flair NER English model](https://huggingface.co/flair/ner-english) to identify entities in our landmine tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917972d9",
   "metadata": {},
   "source": [
    "This is the standard 4-class NER model for English that ships with Flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4bf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86a25f",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2542e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mm_tweet_topics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9a93a",
   "metadata": {},
   "source": [
    "# TNER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c5db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tner import TransformersNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad774a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 18:32:15 INFO     initialize language model with `tner/bert-large-tweetner7-2020`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34591adcdfab41e6a99e03f8c40570bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9908080126af45adb6e04017d6486760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 18:32:47 INFO     use CRF\n",
      "2023-02-16 18:32:47 INFO     loading pre-trained CRF layer\n",
      "2023-02-16 18:32:47 INFO     label2id: {'B-corporation': 0, 'B-creative_work': 1, 'B-event': 2, 'B-group': 3, 'B-location': 4, 'B-person': 5, 'B-product': 6, 'I-corporation': 7, 'I-creative_work': 8, 'I-event': 9, 'I-group': 10, 'I-location': 11, 'I-person': 12, 'I-product': 13, 'O': 14}\n",
      "2023-02-16 18:32:47 INFO     device   : cpu\n",
      "2023-02-16 18:32:47 INFO     gpus     : 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fa74bbcdcf470a8b4a37bf95edbbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad63ea1828c440de9715ba2b9573f30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ea14e9d17c4370afd884ad4210b3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/653k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4804f340667e4c3e89f7393136250d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Get the all-analog Classic Vinyl Edition of `Takin' Off` Album from @herbiehancock via @bluenoterecords link below: http://bluenote.lnk.to/AlbumOfTheWeek\"\n",
    "model = TransformersNER(\"tner/bert-large-tweetner7-2020\")\n",
    "#model.predict([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899fc48",
   "metadata": {},
   "source": [
    "## Run model for one tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d7e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(i, model_dict):\n",
    "    results_dict =  {\n",
    "    'prediction' : model_dict['prediction'][0][i],\n",
    "    'probability' : model_dict['probability'][0][i],\n",
    "    'input' : model_dict['input'][0][i]}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d71eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5e12711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 19:10:48 INFO     encode all the data: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "2023-02-16 19:10:48 INFO     encode all the data: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tner_records = []\n",
    "for row_dict in sample.to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in [model.predict([row_dict[\"tweet_pp\"]])]:\n",
    "        for i in range(len(ner_tag_dict['prediction'][0])):\n",
    "                results_dict = create_dict(i, ner_tag_dict)\n",
    "                tner_records.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1abdd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1511441598030270474, 'foundation_name': 'NUGMyanmar', 'tweet': 'rt is deeply concerned about china s recent effort to establish a partnership with myanmar s illegitimate and g ', 'tweet_date': '2022-04-05', 'tweeted_by_foundation': True, 'query_term': '@NUGMyanmar', 'handle_type': 'Govt', 'region': 'Myanmar', 'tweet_pp': ' is deeply concerned about china s recent effo to establish a panership with myanmar s illegitimate and g ', 'Topic': 0, 'Count': 95, 'Name': '0_myanmar_burma_military_myanmars'}\n",
      "{'id': 1511388284492079118, 'foundation_name': 'cvdom2021', 'tweet': 'rt myanmar s democratically elected government which actually represents the people of myanmar has e ', 'tweet_date': '2022-04-05', 'tweeted_by_foundation': True, 'query_term': '@cvdom2021', 'handle_type': 'Movement', 'region': 'Myanmar', 'tweet_pp': ' myanmar s democratically elected government which actually represents the people of myanmar has e ', 'Topic': 0, 'Count': 95, 'Name': '0_myanmar_burma_military_myanmars'}\n"
     ]
    }
   ],
   "source": [
    "for row_dict in sample.to_dict(orient=\"records\"):\n",
    "    print(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "945bba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 19:13:23 INFO     encode all the data: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "2023-02-16 19:13:23 INFO     encode all the data: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "tner_records = []\n",
    "for row_dict in sample.to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in [model.predict([row_dict[\"tweet_pp\"]])]:\n",
    "        for i in range(len(ner_tag_dict['prediction'][0])):\n",
    "                results_dict = create_dict(i, ner_tag_dict)\n",
    "                row_dict.update(results_dict)\n",
    "                ner_records.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a8b7a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tner_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f58f8",
   "metadata": {},
   "source": [
    "# Run model for one tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349eb09",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043d6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mm_tweet_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_records = []\n",
    "for row_dict in df[1:3].to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in tagger.predict(Sentence(row_dict[\"tweet_pp\"])):  # I Don't recall exact ner model function call\n",
    "        row_dict.update(ner_tag_dict)\n",
    "        ner_records.append(row_dict)\n",
    "ner_df = pd.DataFrame(ner_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65faaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_records = []\n",
    "for row_dict in df.to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in nlp(row_dict[\"tweet_pp\"]):  # I Don't recall exact ner model function call\n",
    "        ner_records.append({**row_dict, **ner_tag_dict})\n",
    "ner_df2 = pd.DataFrame(ner_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3862f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ner_df2[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a95691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_dict(orient=\"records\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eccba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_dict in df.to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in nlp(row_dict[\"tweet_pp\"]):\n",
    "        print(ner_tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_dict in df.to_dict(orient=\"records\"):\n",
    "    for ner_tag_dict in nlp(row_dict[\"tweet_pp\"]):\n",
    "        ner_records.append(row_dict.update(ner_tag_dict))\n",
    "        print(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb31d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec0f02",
   "metadata": {},
   "source": [
    "Row by row - convert to dict\n",
    "Get NER tag output as list of dictionaries\n",
    "1 to many function\n",
    "1 row for every tag\n",
    "Combine text with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df[\"ner\"][3][0].update( df.iloc[3].to_dict())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e709f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = df[df[\"ner\"].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c33161",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty = df[df[\"ner\"].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8581766",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty[\"region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ner\"df[\"region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54132fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty[\"region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de8a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbcd1b9b",
   "metadata": {},
   "source": [
    "# FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829c6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27e8ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bertopic_gpu/lib/python3.7/site-packages/huggingface_hub/file_download.py:591: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f887df5aafde4e07a5f9fa82650a0250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/432M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-14 19:14:16,983 loading file /home/ubuntu/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2023-02-14 19:14:19,716 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence: \"George Washington went to Washington\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n",
      "The following NER tags are found:\n",
      "Span[0:2]: \"George Washington\" → PER (0.9985)\n",
      "Span[4:5]: \"Washington\" → LOC (0.9706)\n"
     ]
    }
   ],
   "source": [
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-english\")\n",
    "\n",
    "# make example sentence\n",
    "sentence = Sentence(\"George Washington went to Washington\")\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e385d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.predict(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic_gpu",
   "language": "python",
   "name": "bertopic_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
