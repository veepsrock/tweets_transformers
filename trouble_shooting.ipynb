{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d387f3-94ec-4a4e-8cde-c28201e74eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 17:42:21.447842: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/oracle/instantclient_12_1:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:\n",
      "2023-03-24 17:42:21.447883: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# read in libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import datetime as dt\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from tner import TransformersNER\n",
    "\n",
    "# connect to sql\n",
    "from mysql.connector import (connection)\n",
    "from mysql.connector import Error\n",
    "\n",
    "# load functions\n",
    "with open('project_config.json','r') as fp: \n",
    "    project_config = json.load(fp)\n",
    "\n",
    "module_path = os.path.join(project_config['project_module_relative_path'])\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from ner.ner_processing import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SQL connection ------------------------------------------------------------------\n",
    "\n",
    "# fetch values from environment variables and set the target database\n",
    "hostname = os.environ['MYSQL_HOST']\n",
    "username = os.environ['MYSQL_USER']\n",
    "password = os.environ['MYSQL_PASSWORD']\n",
    "dbname = 'found'\n",
    "\n",
    "# establish connection to db1 database in your mysql service\n",
    "cnx = connection.MySQLConnection(user=username,\n",
    "                                 password=password,\n",
    "                                 host=hostname,\n",
    "                                 database=dbname)\n",
    "\n",
    "# connect to sql\n",
    "from mysql.connector import (connection)\n",
    "from mysql.connector import Error\n",
    "\n",
    "# fetch values from environment variables and set the target database\n",
    "hostname = os.environ['MYSQL_HOST']\n",
    "username = os.environ['MYSQL_USER']\n",
    "password = os.environ['MYSQL_PASSWORD']\n",
    "dbname = 'found'\n",
    "\n",
    "# establish connection to db1 database in your mysql service\n",
    "cnx = connection.MySQLConnection(user=username,\n",
    "                                 password=password,\n",
    "                                 host=hostname,\n",
    "                                 database=dbname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7fbed8-f59e-4fbb-8885-46457e9f1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query database ---------------------------------------------------------------------\n",
    "query =(\"SELECT * FROM landmine_tweets WHERE date > CURDATE() - INTERVAL 2 day\")\n",
    "\n",
    "#write to df and remove duplicates\n",
    "df = pd.read_sql_query(query, cnx)\n",
    "df = df.drop_duplicates(subset=['tweet', 'handle'], keep=\"first\")\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd9f7f3-6114-4ba2-b23f-e2b5ca3d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect language --------------------------------------------------------------------\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324ba290-561c-4596-be30-136de17c56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy nlp model\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)\n",
    "\n",
    "# create a language column on dataframe\n",
    "df[\"language\"]= df[\"tweet\"].apply(get_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2948d6-dce1-4b49-9246-1ef8ecc665b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/ner/ner_processing.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].str.lower()\n",
      "src/ner/ner_processing.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))\n",
      "src/ner/ner_processing.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub('\\\\[^\\s]*', ' ', x))\n",
      "src/ner/ner_processing.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub('\\n', ' ', x))\n",
      "src/ner/ner_processing.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub('pic.twitter.com\\/[^\\s]*', ' ', x))\n",
      "src/ner/ner_processing.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub('blog\\/maps\\/info\\/[^\\s]*', ' ', x))\n",
      "src/ner/ner_processing.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"\\#[\\w]*\", \"\", x))\n",
      "src/ner/ner_processing.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"\\&amp;\", \"\", x))\n",
      "src/ner/ner_processing.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"\\@[\\w]*\", \"\", x))\n",
      "src/ner/ner_processing.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"'\", \"\", x))\n",
      "src/ner/ner_processing.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"'\", \"\", x))\n",
      "src/ner/ner_processing.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"[^\\w\\d]\", \" \", x))\n",
      "src/ner/ner_processing.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"\\s{2,6}\", \" \", x))\n",
      "src/ner/ner_processing.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tweets] = df[tweets].map(lambda x: re.sub(\"\\s{3,20}\", \"\", x))\n"
     ]
    }
   ],
   "source": [
    "# separate dataframe by eng and non eng tweets --------------------------------------------\n",
    "# create dataframe for non english tweets\n",
    "non_eng = df[df[\"language\"] != \"en\"]\n",
    "\n",
    "# write to csv\n",
    "#non_eng.to_csv(\"landmine_tweets_non_eng_processed.csv\", index = False)\n",
    "\n",
    "# create dataframe for english tweets\n",
    "en = df[df[\"language\"]==\"en\"]\n",
    "\n",
    "# clean text on english tweets\n",
    "en =  clean_tweets(en, 'tweet')\n",
    "\n",
    "# write to csv\n",
    "#en.to_csv(\"landmine_tweets_eng_processed.csv\", index = False)\n",
    "\n",
    "# write back to main tweeets file\n",
    "main = pd.read_csv(\"main.csv\")\n",
    "main = pd.concat([non_eng, en, main])\n",
    "#main.to_csv(\"main.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a486212f-6f35-4b32-bf3c-ef91e5783231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-english tags\n"
     ]
    }
   ],
   "source": [
    "if non_eng.shape[0]!=0:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # apply ner model for non eng tweets\n",
    "    non_eng[\"ner\"] = non_eng[\"tweet\"].apply(nlp)\n",
    "\n",
    "    # list comprehension to combine all ner records\n",
    "    ner_records = []\n",
    "    for row_dict in non_eng.to_dict(orient=\"records\"):\n",
    "        for ner_tag_dict in nlp(row_dict[\"tweet\"]):  # I Don't recall exact ner model function call\n",
    "            ner_records.append({**row_dict, **ner_tag_dict})\n",
    "\n",
    "    # create ner tag df\n",
    "    ner_df = create_ner_tag_df_multi(ner_records, \"Davlan/bert-base-multilingual-cased-ner-hrl\")\n",
    "\n",
    "    # removing all English characters from ner tag df because the multilingual model isn't great for English text\n",
    "\n",
    "    # detect language of ner tags\n",
    "    ner_df[\"language\"]= ner_df[\"tagged_text\"].apply(isEnglish)\n",
    "\n",
    "    # drop English rows\n",
    "    ner_df= ner_df[ner_df[\"language\"] == False].drop(columns=\"language\", axis=True)\n",
    "\n",
    "    # cleaning text\n",
    "    ner_df['tagged_text'] = ner_df['tagged_text'].fillna(\" \")\n",
    "    ner_df['tagged_text'] = ner_df[\"tagged_text\"].str.replace(\"##\", \"\")\n",
    "\n",
    "    # recombine NER tags\n",
    "    ner_df_combined = combine_ner_tags(ner_df, \"\")\n",
    "\n",
    "    # write to csv\n",
    "    #ner_df.to_csv(\"landmine_tweets_ner_results_non_eng_clean.csv\", index = False)\n",
    "\n",
    "else:\n",
    "    print(\"No non-English tweets today\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4aca614-53a6-4c1a-8cf5-250b64add1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = create_ner_tag_df_multi(ner_records, \"Davlan/bert-base-multilingual-cased-ner-hrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db2e2be-8516-40ba-853d-da4626df215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df[\"language\"]= ner_df[\"tagged_text\"].apply(isEnglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a7efd8-7575-43fe-a454-d605d4315abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    9\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75eada54-b733-4a23-ba25-32c805e2cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine ner tags\n",
    "def combine_ner_tags(df, spacer):\n",
    "    \"\"\"\n",
    "    Function to recombine NER tags from B- to I-\n",
    "    df = dataframe\n",
    "    spacer = what kind of spacing to use to combine text. Use \"\" for non english and \" \" for english\n",
    "    \"\"\"\n",
    "    combined_tokens = []\n",
    "    df = df.reset_index()\n",
    "    if df.shape[0] !=0:\n",
    "        if df.iloc[0][\"ner_tag\"].startswith(\"I-\"):\n",
    "            df=df.iloc[1:,]\n",
    "        df = df.reset_index()\n",
    "        cur_tokens = [df.loc[0, \"tagged_text\"]]\n",
    "        for i in range(1, len(df)):\n",
    "            if df.loc[i, \"ner_tag\"].startswith(\"B-\"):\n",
    "                combined_tokens.append(cur_tokens)\n",
    "                cur_tokens = [df.loc[i, \"tagged_text\"]]\n",
    "            elif df.loc[i, \"ner_tag\"].startswith(\"I-\"):\n",
    "                 cur_tokens.append(df.loc[i, \"tagged_text\"])\n",
    "        b_tags = df[df[\"ner_tag\"].str.startswith(\"B-\")]\n",
    "        combined_tokens.append([b_tags.tail(1)[\"tagged_text\"].values[0]])\n",
    "        # update the combined text join based on which language. no space for non_eng\n",
    "        combined_text = [spacer.join(i) for i in combined_tokens]\n",
    "        b_tags[\"tagged_text\"] = combined_text\n",
    "        return b_tags\n",
    "    else:\n",
    "        print(\"No non-english tags\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103528da-f693-413b-adc1-2590688440a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553/1065089801.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b_tags[\"tagged_text\"] = combined_text\n"
     ]
    }
   ],
   "source": [
    "ner_df_combined = combine_ner_tags(ner_df, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d69afb-4fa6-48bb-bcb9-483027fee294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>tagged_text</th>\n",
       "      <th>ner_tag</th>\n",
       "      <th>tagged_text_loci</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>probability</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1638752507802554368</td>\n",
       "      <td>1</td>\n",
       "      <td>Sebagai warga RoG yang mayoritas Muhammadiyah ...</td>\n",
       "      <td>R##o##G</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>Davlan/bert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1638752507802554368</td>\n",
       "      <td>1</td>\n",
       "      <td>Sebagai warga RoG yang mayoritas Muhammadiyah ...</td>\n",
       "      <td>Muhammad##iyah</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>9</td>\n",
       "      <td>Davlan/bert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1638752507802554368</td>\n",
       "      <td>1</td>\n",
       "      <td>Sebagai warga RoG yang mayoritas Muhammadiyah ...</td>\n",
       "      <td>Muhammad##iyah</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>19</td>\n",
       "      <td>Davlan/bert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1638752507802554368</td>\n",
       "      <td>1</td>\n",
       "      <td>Sebagai warga RoG yang mayoritas Muhammadiyah ...</td>\n",
       "      <td>Howard</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>32</td>\n",
       "      <td>Davlan/bert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index          document_id  sentence_number  \\\n",
       "0        0      0  1638752507802554368                1   \n",
       "3        3      3  1638752507802554368                1   \n",
       "5        5      5  1638752507802554368                1   \n",
       "7        7      7  1638752507802554368                1   \n",
       "\n",
       "                                       sentence_text     tagged_text ner_tag  \\\n",
       "0  Sebagai warga RoG yang mayoritas Muhammadiyah ...         R##o##G   B-ORG   \n",
       "3  Sebagai warga RoG yang mayoritas Muhammadiyah ...  Muhammad##iyah   B-ORG   \n",
       "5  Sebagai warga RoG yang mayoritas Muhammadiyah ...  Muhammad##iyah   B-ORG   \n",
       "7  Sebagai warga RoG yang mayoritas Muhammadiyah ...          Howard   B-PER   \n",
       "\n",
       "  tagged_text_loci                                    ner_model  probability  \\\n",
       "0                3  Davlan/bert-base-multilingual-cased-ner-hrl     0.999267   \n",
       "3                9  Davlan/bert-base-multilingual-cased-ner-hrl     0.999034   \n",
       "5               19  Davlan/bert-base-multilingual-cased-ner-hrl     0.999407   \n",
       "7               32  Davlan/bert-base-multilingual-cased-ner-hrl     0.999777   \n",
       "\n",
       "   language  \n",
       "0      True  \n",
       "3      True  \n",
       "5      True  \n",
       "7      True  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd83833b-35e5-4bde-836f-74634f3c312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78491fc7-5e70-4a34-a64a-9bab9dafe844",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mner_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:895\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    892\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    894\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1501\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1444\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "ner_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d6940-1615-43e0-9664-0d95d3387dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
